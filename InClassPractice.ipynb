{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "mNbVO2h3jI1u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Chapter10ANN/data.csv')"
      ],
      "metadata": {
        "id": "ytOA685tjWOR"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "RvFstDCrjf0d",
        "outputId": "8f9af3fd-612b-47b1-a229-cb3152293d62"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        17.99         10.38          122.80     1001.0   \n",
              "1         M        20.57         17.77          132.90     1326.0   \n",
              "2         M        19.69         21.25          130.00     1203.0   \n",
              "3         M        11.42         20.38           77.58      386.1   \n",
              "4         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.2419  ...         25.38          17.33           184.60   \n",
              "1         0.1812  ...         24.99          23.41           158.80   \n",
              "2         0.2069  ...         23.57          25.53           152.50   \n",
              "3         0.2597  ...         14.91          26.50            98.87   \n",
              "4         0.1809  ...         22.54          16.67           152.20   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-546b9d5c-7a4d-47fc-822e-a8d91ea4f7fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-546b9d5c-7a4d-47fc-822e-a8d91ea4f7fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-546b9d5c-7a4d-47fc-822e-a8d91ea4f7fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-546b9d5c-7a4d-47fc-822e-a8d91ea4f7fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjnRZZCijj58",
        "outputId": "b230a623-b695-4808-c3da-cb39948b220c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 564 entries, 0 to 563\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                564 non-null    object \n",
            " 1   radius_mean              564 non-null    float64\n",
            " 2   texture_mean             564 non-null    float64\n",
            " 3   perimeter_mean           564 non-null    float64\n",
            " 4   area_mean                564 non-null    float64\n",
            " 5   smoothness_mean          564 non-null    float64\n",
            " 6   compactness_mean         564 non-null    float64\n",
            " 7   concavity_mean           564 non-null    float64\n",
            " 8   concave points_mean      564 non-null    float64\n",
            " 9   symmetry_mean            564 non-null    float64\n",
            " 10  fractal_dimension_mean   564 non-null    float64\n",
            " 11  radius_se                564 non-null    float64\n",
            " 12  texture_se               564 non-null    float64\n",
            " 13  perimeter_se             564 non-null    float64\n",
            " 14  area_se                  564 non-null    float64\n",
            " 15  smoothness_se            564 non-null    float64\n",
            " 16  compactness_se           564 non-null    float64\n",
            " 17  concavity_se             564 non-null    float64\n",
            " 18  concave points_se        564 non-null    float64\n",
            " 19  symmetry_se              564 non-null    float64\n",
            " 20  fractal_dimension_se     564 non-null    float64\n",
            " 21  radius_worst             564 non-null    float64\n",
            " 22  texture_worst            564 non-null    float64\n",
            " 23  perimeter_worst          564 non-null    float64\n",
            " 24  area_worst               564 non-null    float64\n",
            " 25  smoothness_worst         564 non-null    float64\n",
            " 26  compactness_worst        564 non-null    float64\n",
            " 27  concavity_worst          564 non-null    float64\n",
            " 28  concave points_worst     564 non-null    float64\n",
            " 29  symmetry_worst           564 non-null    float64\n",
            " 30  fractal_dimension_worst  564 non-null    float64\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 136.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.drop('diagnosis', axis=1)\n",
        "y = data[['diagnosis']]"
      ],
      "metadata": {
        "id": "zOJ9oeFKjsFi"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()\n",
        "y = LE.fit_transform(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiqH2l39BP5C",
        "outputId": "ac4ff0aa-045b-4fb3-b25f-accac488f5e5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data"
      ],
      "metadata": {
        "id": "MDUSnlpbtQXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "YSeAEkfWs84T"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling the data"
      ],
      "metadata": {
        "id": "fi2gcAo6Fbx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x=StandardScaler()\n",
        "x_train=sc_x.fit_transform(x_train)\n",
        "x_test=sc_x.transform(x_test)"
      ],
      "metadata": {
        "id": "j_MrvFA9FbVc"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build ANN Model"
      ],
      "metadata": {
        "id": "lSbizu5otk4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "SriC9m6UujKo"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = x_train.shape[1]\n",
        "print(n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFo3dNvQwI_o",
        "outputId": "875e271e-fb70-46e8-968b-eb380b4385d3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_features,)))"
      ],
      "metadata": {
        "id": "clUFCPAywb7K"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "eb7KVNK5w8EL"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "rO_bkmzgxW1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "U9F9PR0RxVOF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit the model"
      ],
      "metadata": {
        "id": "Rwxux1Kox0TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x_train, y_train, epochs=150, validation_data=(x_test, y_test), batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND2WlzlxxwTo",
        "outputId": "578d7783-1487-4bf2-f25a-6898e78bd4a4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "13/13 [==============================] - 1s 17ms/step - loss: 0.6767 - accuracy: 0.6777 - val_loss: 0.6102 - val_accuracy: 0.7588\n",
            "Epoch 2/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5945 - accuracy: 0.7919 - val_loss: 0.5404 - val_accuracy: 0.8471\n",
            "Epoch 3/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.8503 - val_loss: 0.4740 - val_accuracy: 0.9000\n",
            "Epoch 4/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.8706 - val_loss: 0.4157 - val_accuracy: 0.9118\n",
            "Epoch 5/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8858 - val_loss: 0.3670 - val_accuracy: 0.9294\n",
            "Epoch 6/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3517 - accuracy: 0.9036 - val_loss: 0.3274 - val_accuracy: 0.9353\n",
            "Epoch 7/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3144 - accuracy: 0.9061 - val_loss: 0.2950 - val_accuracy: 0.9412\n",
            "Epoch 8/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.9086 - val_loss: 0.2697 - val_accuracy: 0.9412\n",
            "Epoch 9/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2584 - accuracy: 0.9188 - val_loss: 0.2486 - val_accuracy: 0.9353\n",
            "Epoch 10/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2371 - accuracy: 0.9340 - val_loss: 0.2297 - val_accuracy: 0.9412\n",
            "Epoch 11/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2186 - accuracy: 0.9391 - val_loss: 0.2125 - val_accuracy: 0.9412\n",
            "Epoch 12/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2031 - accuracy: 0.9467 - val_loss: 0.1969 - val_accuracy: 0.9412\n",
            "Epoch 13/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9492 - val_loss: 0.1844 - val_accuracy: 0.9412\n",
            "Epoch 14/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1758 - accuracy: 0.9543 - val_loss: 0.1721 - val_accuracy: 0.9412\n",
            "Epoch 15/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9543 - val_loss: 0.1607 - val_accuracy: 0.9529\n",
            "Epoch 16/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.9543 - val_loss: 0.1515 - val_accuracy: 0.9529\n",
            "Epoch 17/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9619 - val_loss: 0.1431 - val_accuracy: 0.9529\n",
            "Epoch 18/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9645 - val_loss: 0.1347 - val_accuracy: 0.9529\n",
            "Epoch 19/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9670 - val_loss: 0.1279 - val_accuracy: 0.9529\n",
            "Epoch 20/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9695 - val_loss: 0.1221 - val_accuracy: 0.9529\n",
            "Epoch 21/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9721 - val_loss: 0.1166 - val_accuracy: 0.9647\n",
            "Epoch 22/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9721 - val_loss: 0.1115 - val_accuracy: 0.9647\n",
            "Epoch 23/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1048 - accuracy: 0.9746 - val_loss: 0.1075 - val_accuracy: 0.9647\n",
            "Epoch 24/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9746 - val_loss: 0.1033 - val_accuracy: 0.9706\n",
            "Epoch 25/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9772 - val_loss: 0.1004 - val_accuracy: 0.9706\n",
            "Epoch 26/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9772 - val_loss: 0.0975 - val_accuracy: 0.9706\n",
            "Epoch 27/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9797 - val_loss: 0.0951 - val_accuracy: 0.9706\n",
            "Epoch 28/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9797 - val_loss: 0.0930 - val_accuracy: 0.9706\n",
            "Epoch 29/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0830 - accuracy: 0.9772 - val_loss: 0.0906 - val_accuracy: 0.9706\n",
            "Epoch 30/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9772 - val_loss: 0.0893 - val_accuracy: 0.9647\n",
            "Epoch 31/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9772 - val_loss: 0.0879 - val_accuracy: 0.9647\n",
            "Epoch 32/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.0865 - val_accuracy: 0.9647\n",
            "Epoch 33/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9772 - val_loss: 0.0852 - val_accuracy: 0.9588\n",
            "Epoch 34/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9772 - val_loss: 0.0840 - val_accuracy: 0.9588\n",
            "Epoch 35/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9772 - val_loss: 0.0827 - val_accuracy: 0.9588\n",
            "Epoch 36/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9772 - val_loss: 0.0814 - val_accuracy: 0.9588\n",
            "Epoch 37/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 0.0802 - val_accuracy: 0.9647\n",
            "Epoch 38/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0643 - accuracy: 0.9772 - val_loss: 0.0795 - val_accuracy: 0.9647\n",
            "Epoch 39/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9797 - val_loss: 0.0789 - val_accuracy: 0.9647\n",
            "Epoch 40/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9797 - val_loss: 0.0786 - val_accuracy: 0.9647\n",
            "Epoch 41/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9797 - val_loss: 0.0782 - val_accuracy: 0.9706\n",
            "Epoch 42/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0585 - accuracy: 0.9848 - val_loss: 0.0777 - val_accuracy: 0.9647\n",
            "Epoch 43/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9848 - val_loss: 0.0782 - val_accuracy: 0.9647\n",
            "Epoch 44/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9873 - val_loss: 0.0780 - val_accuracy: 0.9647\n",
            "Epoch 45/150\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9873 - val_loss: 0.0782 - val_accuracy: 0.9647\n",
            "Epoch 46/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9873 - val_loss: 0.0783 - val_accuracy: 0.9647\n",
            "Epoch 47/150\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9873 - val_loss: 0.0777 - val_accuracy: 0.9647\n",
            "Epoch 48/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9873 - val_loss: 0.0779 - val_accuracy: 0.9647\n",
            "Epoch 49/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9873 - val_loss: 0.0784 - val_accuracy: 0.9588\n",
            "Epoch 50/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9873 - val_loss: 0.0782 - val_accuracy: 0.9588\n",
            "Epoch 51/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9873 - val_loss: 0.0786 - val_accuracy: 0.9588\n",
            "Epoch 52/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9873 - val_loss: 0.0798 - val_accuracy: 0.9588\n",
            "Epoch 53/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9873 - val_loss: 0.0803 - val_accuracy: 0.9529\n",
            "Epoch 54/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9873 - val_loss: 0.0803 - val_accuracy: 0.9529\n",
            "Epoch 55/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9873 - val_loss: 0.0806 - val_accuracy: 0.9529\n",
            "Epoch 56/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 0.0804 - val_accuracy: 0.9529\n",
            "Epoch 57/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9898 - val_loss: 0.0813 - val_accuracy: 0.9529\n",
            "Epoch 58/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9898 - val_loss: 0.0811 - val_accuracy: 0.9529\n",
            "Epoch 59/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.0826 - val_accuracy: 0.9529\n",
            "Epoch 60/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9924 - val_loss: 0.0817 - val_accuracy: 0.9529\n",
            "Epoch 61/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9924 - val_loss: 0.0834 - val_accuracy: 0.9529\n",
            "Epoch 62/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9898 - val_loss: 0.0824 - val_accuracy: 0.9529\n",
            "Epoch 63/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9924 - val_loss: 0.0816 - val_accuracy: 0.9529\n",
            "Epoch 64/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9898 - val_loss: 0.0859 - val_accuracy: 0.9529\n",
            "Epoch 65/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9898 - val_loss: 0.0859 - val_accuracy: 0.9529\n",
            "Epoch 66/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9924 - val_loss: 0.0854 - val_accuracy: 0.9529\n",
            "Epoch 67/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9924 - val_loss: 0.0840 - val_accuracy: 0.9529\n",
            "Epoch 68/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9924 - val_loss: 0.0887 - val_accuracy: 0.9529\n",
            "Epoch 69/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9924 - val_loss: 0.0897 - val_accuracy: 0.9529\n",
            "Epoch 70/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9924 - val_loss: 0.0889 - val_accuracy: 0.9529\n",
            "Epoch 71/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9924 - val_loss: 0.0890 - val_accuracy: 0.9529\n",
            "Epoch 72/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9924 - val_loss: 0.0896 - val_accuracy: 0.9529\n",
            "Epoch 73/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9924 - val_loss: 0.0902 - val_accuracy: 0.9529\n",
            "Epoch 74/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9924 - val_loss: 0.0917 - val_accuracy: 0.9529\n",
            "Epoch 75/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9924 - val_loss: 0.0913 - val_accuracy: 0.9529\n",
            "Epoch 76/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 0.0917 - val_accuracy: 0.9529\n",
            "Epoch 77/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9924 - val_loss: 0.0929 - val_accuracy: 0.9529\n",
            "Epoch 78/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.0977 - val_accuracy: 0.9529\n",
            "Epoch 79/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.0966 - val_accuracy: 0.9529\n",
            "Epoch 80/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9924 - val_loss: 0.0956 - val_accuracy: 0.9529\n",
            "Epoch 81/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.0953 - val_accuracy: 0.9529\n",
            "Epoch 82/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.0981 - val_accuracy: 0.9529\n",
            "Epoch 83/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.1000 - val_accuracy: 0.9529\n",
            "Epoch 84/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.1002 - val_accuracy: 0.9529\n",
            "Epoch 85/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0999 - val_accuracy: 0.9529\n",
            "Epoch 86/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.1012 - val_accuracy: 0.9529\n",
            "Epoch 87/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.1019 - val_accuracy: 0.9529\n",
            "Epoch 88/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.1009 - val_accuracy: 0.9529\n",
            "Epoch 89/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1030 - val_accuracy: 0.9529\n",
            "Epoch 90/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.1039 - val_accuracy: 0.9529\n",
            "Epoch 91/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.1020 - val_accuracy: 0.9529\n",
            "Epoch 92/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.1046 - val_accuracy: 0.9529\n",
            "Epoch 93/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.1034 - val_accuracy: 0.9529\n",
            "Epoch 94/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.1037 - val_accuracy: 0.9529\n",
            "Epoch 95/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.1081 - val_accuracy: 0.9588\n",
            "Epoch 96/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 0.1064 - val_accuracy: 0.9588\n",
            "Epoch 97/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.1030 - val_accuracy: 0.9588\n",
            "Epoch 98/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.1041 - val_accuracy: 0.9588\n",
            "Epoch 99/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.1035 - val_accuracy: 0.9588\n",
            "Epoch 100/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.1048 - val_accuracy: 0.9588\n",
            "Epoch 101/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.1056 - val_accuracy: 0.9588\n",
            "Epoch 102/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.1078 - val_accuracy: 0.9588\n",
            "Epoch 103/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.1066 - val_accuracy: 0.9588\n",
            "Epoch 104/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.1053 - val_accuracy: 0.9588\n",
            "Epoch 105/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1084 - val_accuracy: 0.9588\n",
            "Epoch 106/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.1085 - val_accuracy: 0.9588\n",
            "Epoch 107/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1098 - val_accuracy: 0.9588\n",
            "Epoch 108/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.1104 - val_accuracy: 0.9588\n",
            "Epoch 109/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.1174 - val_accuracy: 0.9588\n",
            "Epoch 110/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.1155 - val_accuracy: 0.9588\n",
            "Epoch 111/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.1124 - val_accuracy: 0.9588\n",
            "Epoch 112/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.1126 - val_accuracy: 0.9588\n",
            "Epoch 113/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9975 - val_loss: 0.1135 - val_accuracy: 0.9588\n",
            "Epoch 114/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.1105 - val_accuracy: 0.9588\n",
            "Epoch 115/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1136 - val_accuracy: 0.9588\n",
            "Epoch 116/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.1142 - val_accuracy: 0.9588\n",
            "Epoch 117/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.1142 - val_accuracy: 0.9588\n",
            "Epoch 118/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.1128 - val_accuracy: 0.9588\n",
            "Epoch 119/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.1160 - val_accuracy: 0.9588\n",
            "Epoch 120/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.1153 - val_accuracy: 0.9588\n",
            "Epoch 121/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.1161 - val_accuracy: 0.9588\n",
            "Epoch 122/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.1196 - val_accuracy: 0.9588\n",
            "Epoch 123/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9975 - val_loss: 0.1185 - val_accuracy: 0.9588\n",
            "Epoch 124/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9975 - val_loss: 0.1181 - val_accuracy: 0.9588\n",
            "Epoch 125/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.1183 - val_accuracy: 0.9588\n",
            "Epoch 126/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 0.1201 - val_accuracy: 0.9588\n",
            "Epoch 127/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.1205 - val_accuracy: 0.9588\n",
            "Epoch 128/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.1227 - val_accuracy: 0.9588\n",
            "Epoch 129/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.1209 - val_accuracy: 0.9588\n",
            "Epoch 130/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.1198 - val_accuracy: 0.9529\n",
            "Epoch 131/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.1199 - val_accuracy: 0.9529\n",
            "Epoch 132/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.1226 - val_accuracy: 0.9529\n",
            "Epoch 133/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 0.1218 - val_accuracy: 0.9529\n",
            "Epoch 134/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.1236 - val_accuracy: 0.9529\n",
            "Epoch 135/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1242 - val_accuracy: 0.9529\n",
            "Epoch 136/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1244 - val_accuracy: 0.9529\n",
            "Epoch 137/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.1253 - val_accuracy: 0.9529\n",
            "Epoch 138/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.1246 - val_accuracy: 0.9529\n",
            "Epoch 139/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.1241 - val_accuracy: 0.9529\n",
            "Epoch 140/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.1253 - val_accuracy: 0.9529\n",
            "Epoch 141/150\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.1260 - val_accuracy: 0.9529\n",
            "Epoch 142/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1395 - val_accuracy: 0.9529\n",
            "Epoch 143/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.1375 - val_accuracy: 0.9529\n",
            "Epoch 144/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.1313 - val_accuracy: 0.9529\n",
            "Epoch 145/150\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.1310 - val_accuracy: 0.9529\n",
            "Epoch 146/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9975 - val_loss: 0.1318 - val_accuracy: 0.9529\n",
            "Epoch 147/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1322 - val_accuracy: 0.9529\n",
            "Epoch 148/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.1326 - val_accuracy: 0.9529\n",
            "Epoch 149/150\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.1328 - val_accuracy: 0.9529\n",
            "Epoch 150/150\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1352 - val_accuracy: 0.9529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzQU846rEMaF"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1I4o9jAlENP1"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Validation"
      ],
      "metadata": {
        "id": "du0JaXQfykWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "print(f\"The loss is {loss}, The accuracy is {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48daWfQCCiPg",
        "outputId": "adfa9983-4ddc-43e1-d07b-5c3936d6e76b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9529\n",
            "The loss is 0.1352183222770691, The accuracy is 0.9529411792755127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot accuracy and Loss"
      ],
      "metadata": {
        "id": "Fh0zbHpNEgDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "z2VlKplDEncc",
        "outputId": "4e6f0a0b-95a0-4fd0-eaec-6b28a8ab88ad"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "J_9onEH5Epbn",
        "outputId": "e7d1e3ee-ff5b-4919-9aa5-1b781550408d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix and Classification report"
      ],
      "metadata": {
        "id": "h48MiJyr1Il6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred>0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuJaWCPkEsk9",
        "outputId": "d519b221-23b3-4070-904f-d813401ec751"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVC9b6XyEv5j",
        "outputId": "b06e237d-31f7-486f-ea95-9eedc8ac4882"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[100   3]\n",
            " [  5  62]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoGpNsTlExvE",
        "outputId": "22abefdb-e635-482e-de88-3e356685df90"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       103\n",
            "           1       0.95      0.93      0.94        67\n",
            "\n",
            "    accuracy                           0.95       170\n",
            "   macro avg       0.95      0.95      0.95       170\n",
            "weighted avg       0.95      0.95      0.95       170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate"
      ],
      "metadata": {
        "id": "oPAm7oQ-E6MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validate = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Chapter10ANN/Validate.csv')\n",
        "valid_list = validate.values.tolist()\n",
        "print(valid_list)\n",
        "validate.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "hdWNh0jmGRHh",
        "outputId": "d8a6266e-81cc-4d72-a0fc-7df225d73e83"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['M', 14.68, 20.13, 94.74, 684.5, 0.09867, 0.072, 0.07395, 0.05259, 0.1586, 0.05922, 0.4727, 1.24, 3.195, 45.4, 0.005718, 0.01162, 0.01998, 0.01109, 0.0141, 0.002085, 19.07, 30.88, 123.4, 1138.0, 0.1464, 0.1871, 0.2914, 0.1609, 0.3029, 0.08216], ['M', 16.13, 20.68, 108.1, 798.8, 0.117, 0.2022, 0.1722, 0.1028, 0.2164, 0.07356, 0.5692, 1.073, 3.854, 54.18, 0.007026, 0.02501, 0.03188, 0.01297, 0.01689, 0.004142, 20.96, 31.48, 136.8, 1315.0, 0.1789, 0.4233, 0.4784, 0.2073, 0.3706, 0.1142], ['M', 19.81, 22.15, 130.0, 1260.0, 0.09831, 0.1027, 0.1479, 0.09498, 0.1582, 0.05395, 0.7582, 1.017, 5.865, 112.4, 0.006494, 0.01893, 0.03391, 0.01521, 0.01356, 0.001997, 27.32, 30.88, 186.8, 2398.0, 0.1512, 0.315, 0.5372, 0.2388, 0.2768, 0.07615], ['B', 13.54, 14.36, 87.46, 566.3, 0.09779, 0.08129, 0.06664, 0.04781, 0.1885, 0.05766, 0.2699, 0.7886, 2.058, 23.56, 0.008462, 0.0146, 0.02387, 0.01315, 0.0198, 0.0023, 15.11, 19.26, 99.7, 711.2, 0.144, 0.1773, 0.239, 0.1288, 0.2977, 0.07259], ['B', 13.08, 15.71, 85.63, 520.0, 0.1075, 0.127, 0.04568, 0.0311, 0.1967, 0.06811, 0.1852, 0.7477, 1.383, 14.67, 0.004097, 0.01898, 0.01698, 0.00649, 0.01678, 0.002425, 14.5, 20.49, 96.09, 630.5, 0.1312, 0.2776, 0.189, 0.07283, 0.3184, 0.08183]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0         M        14.68         20.13           94.74      684.5   \n",
              "1         M        16.13         20.68          108.10      798.8   \n",
              "2         M        19.81         22.15          130.00     1260.0   \n",
              "3         B        13.54         14.36           87.46      566.3   \n",
              "4         B        13.08         15.71           85.63      520.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.09867           0.07200         0.07395              0.05259   \n",
              "1          0.11700           0.20220         0.17220              0.10280   \n",
              "2          0.09831           0.10270         0.14790              0.09498   \n",
              "3          0.09779           0.08129         0.06664              0.04781   \n",
              "4          0.10750           0.12700         0.04568              0.03110   \n",
              "\n",
              "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
              "0         0.1586  ...         19.07          30.88           123.40   \n",
              "1         0.2164  ...         20.96          31.48           136.80   \n",
              "2         0.1582  ...         27.32          30.88           186.80   \n",
              "3         0.1885  ...         15.11          19.26            99.70   \n",
              "4         0.1967  ...         14.50          20.49            96.09   \n",
              "\n",
              "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
              "0      1138.0            0.1464             0.1871           0.2914   \n",
              "1      1315.0            0.1789             0.4233           0.4784   \n",
              "2      2398.0            0.1512             0.3150           0.5372   \n",
              "3       711.2            0.1440             0.1773           0.2390   \n",
              "4       630.5            0.1312             0.2776           0.1890   \n",
              "\n",
              "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
              "0               0.16090          0.3029                  0.08216  \n",
              "1               0.20730          0.3706                  0.11420  \n",
              "2               0.23880          0.2768                  0.07615  \n",
              "3               0.12880          0.2977                  0.07259  \n",
              "4               0.07283          0.3184                  0.08183  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6283011-450c-4b64-a769-f92f771026f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>14.68</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>0.1586</td>\n",
              "      <td>...</td>\n",
              "      <td>19.07</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>16.13</td>\n",
              "      <td>20.68</td>\n",
              "      <td>108.10</td>\n",
              "      <td>798.8</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.20220</td>\n",
              "      <td>0.17220</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.2164</td>\n",
              "      <td>...</td>\n",
              "      <td>20.96</td>\n",
              "      <td>31.48</td>\n",
              "      <td>136.80</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>0.4233</td>\n",
              "      <td>0.4784</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.3706</td>\n",
              "      <td>0.11420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.81</td>\n",
              "      <td>22.15</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.09831</td>\n",
              "      <td>0.10270</td>\n",
              "      <td>0.14790</td>\n",
              "      <td>0.09498</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>...</td>\n",
              "      <td>27.32</td>\n",
              "      <td>30.88</td>\n",
              "      <td>186.80</td>\n",
              "      <td>2398.0</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.5372</td>\n",
              "      <td>0.23880</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.07615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>13.54</td>\n",
              "      <td>14.36</td>\n",
              "      <td>87.46</td>\n",
              "      <td>566.3</td>\n",
              "      <td>0.09779</td>\n",
              "      <td>0.08129</td>\n",
              "      <td>0.06664</td>\n",
              "      <td>0.04781</td>\n",
              "      <td>0.1885</td>\n",
              "      <td>...</td>\n",
              "      <td>15.11</td>\n",
              "      <td>19.26</td>\n",
              "      <td>99.70</td>\n",
              "      <td>711.2</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.12880</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.07259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B</td>\n",
              "      <td>13.08</td>\n",
              "      <td>15.71</td>\n",
              "      <td>85.63</td>\n",
              "      <td>520.0</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.12700</td>\n",
              "      <td>0.04568</td>\n",
              "      <td>0.03110</td>\n",
              "      <td>0.1967</td>\n",
              "      <td>...</td>\n",
              "      <td>14.50</td>\n",
              "      <td>20.49</td>\n",
              "      <td>96.09</td>\n",
              "      <td>630.5</td>\n",
              "      <td>0.1312</td>\n",
              "      <td>0.2776</td>\n",
              "      <td>0.1890</td>\n",
              "      <td>0.07283</td>\n",
              "      <td>0.3184</td>\n",
              "      <td>0.08183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6283011-450c-4b64-a769-f92f771026f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6283011-450c-4b64-a769-f92f771026f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6283011-450c-4b64-a769-f92f771026f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,5):\n",
        "  data = valid_list[i][1:]\n",
        "  print(model.predict(sc_x.transform([data])) > 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r61Tj7-HE7zg",
        "outputId": "76f06dc4-fba5-4d66-d31a-f987bf94ae3e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 87ms/step\n",
            "[[ True]]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "[[ True]]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[ True]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n",
            "[[False]]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "[[False]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    }
  ]
}